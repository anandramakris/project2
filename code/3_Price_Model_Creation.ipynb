{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e4352c2",
   "metadata": {},
   "source": [
    "## In this file, a final model for the data is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "98201f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "27348ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('../datasets/train_cleaned.csv')\n",
    "test = pd.read_csv('../datasets/test_cleaned.csv')\n",
    "\n",
    "train.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "test.drop(columns = 'Unnamed: 0', inplace = True)\n",
    "\n",
    "train = train.fillna('NA')\n",
    "test = test.fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e2f04",
   "metadata": {},
   "source": [
    "I will create binary columns for categorical variables based on the visualization results in file 2 (Introductory Visualizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9efb2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding based on whether the garage is attached to the house\n",
    "train['AttachedGarage'] = train['Garage Type'].isin(['Attchd', 'BuiltIn']).astype(int)\n",
    "test['AttachedGarage'] = test['Garage Type'].isin(['Attchd', 'BuiltIn']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e7e817ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding garage finish\n",
    "garage_finish = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
    "train['Garage Finish'] = train['Garage Finish'].map(lambda x: garage_finish.get(x))\n",
    "test['Garage Finish'] = test['Garage Finish'].map(lambda x: garage_finish.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9a69303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding based on whether the building is residential, as residential buildings are more expensive\n",
    "# Function gotten from documentation: https://pandas.pydata.org/docs/reference/api/pandas.Series.isin.html\n",
    "train['Residential'] = train['MS Zoning'].isin(['RL', 'RM', 'FV', 'RH']).astype(int)\n",
    "test['Residential'] = test['MS Zoning'].isin(['RL', 'RM', 'FV', 'RH']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6357401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding neighborhoods on what seems most upscale based on the data\n",
    "train['Expensive Nbrhd'] = train['Neighborhood'].isin(['StBr', 'NridgHt', 'NoRidge', \n",
    "                                                             'GrnHill', 'Veenker', 'Timber']).astype(int)\n",
    "test['Expensive Nbrhd'] = test['Neighborhood'].isin(['StBr', 'NridgHt', 'NoRidge', \n",
    "                                                           'GrnHill', 'Veenker', 'Timber']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4b7f5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding based on proximity to positive off-site features\n",
    "train['PosProx'] = ((train['Condition 1'].isin(['PosA', 'PosN'])) | (train['Condition 2'].isin(['PosA', 'PosN']))).astype(int)\n",
    "test['PosProx'] = ((test['Condition 1'].isin(['PosA', 'PosN'])) | (test['Condition 2'].isin(['PosA', 'PosN']))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8ab409c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding based on whether the roof is made of wood\n",
    "train['WoodRoof'] = train['Roof Matl'].isin(['WdShngl', 'WdShake']).astype(int)\n",
    "test['WoodRoof'] = test['Roof Matl'].isin(['WdShngl', 'WdShake']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6aa2366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the variables that I have decided on using as predictors from the file 2 visualizations\n",
    "X = train[['Garage Cars', 'AttachedGarage', 'Garage Finish', \n",
    "                 'Overall Qual', 'Overall Cond', 'Year Built', 'Total Bsmt SF',\n",
    "                 'Residential', 'Expensive Nbrhd', 'PosProx', 'Gr Liv Area', 'WoodRoof']]\n",
    "\n",
    "y = train['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "# Scale the data\n",
    "ss = StandardScaler()\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "81adecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79239.33504161824"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the baseline RMSE\n",
    "\n",
    "y_avg = [y.mean()]*len(X)\n",
    "\n",
    "metrics.mean_squared_error(y, y_avg, squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf04e53f",
   "metadata": {},
   "source": [
    "The baseline root mean squared error is 79239, which means we have to get a lower RMSE for our model to be considered passable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "901d4f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Garage Cars</th>\n",
       "      <th>AttachedGarage</th>\n",
       "      <th>Garage Finish</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>Residential</th>\n",
       "      <th>Expensive Nbrhd</th>\n",
       "      <th>PosProx</th>\n",
       "      <th>Gr Liv Area</th>\n",
       "      <th>WoodRoof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coef</th>\n",
       "      <td>8630.012708</td>\n",
       "      <td>1070.170465</td>\n",
       "      <td>2492.953705</td>\n",
       "      <td>24817.563527</td>\n",
       "      <td>6310.819013</td>\n",
       "      <td>11060.041431</td>\n",
       "      <td>10637.679766</td>\n",
       "      <td>-915.51481</td>\n",
       "      <td>13204.14711</td>\n",
       "      <td>4068.523529</td>\n",
       "      <td>23440.441639</td>\n",
       "      <td>1239.134857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Garage Cars  AttachedGarage  Garage Finish  Overall Qual  Overall Cond  \\\n",
       "coef  8630.012708     1070.170465    2492.953705  24817.563527   6310.819013   \n",
       "\n",
       "        Year Built  Total Bsmt SF  Residential  Expensive Nbrhd      PosProx  \\\n",
       "coef  11060.041431   10637.679766   -915.51481      13204.14711  4068.523529   \n",
       "\n",
       "       Gr Liv Area     WoodRoof  \n",
       "coef  23440.441639  1239.134857  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(Xs_train, y_train)\n",
    "\n",
    "df = pd.DataFrame([lr.coef_], columns = X_train.columns, index = ['coef'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd908d7",
   "metadata": {},
   "source": [
    "The three garage parameters have expectedly high coefficients in the linear model, but others are surprising.\n",
    "\n",
    "A residential building actually decreases sale price when compared with a non-residential building, which is odd because the boxes for residential buildings in the boxplot were higher than those for non-residential buildings.\n",
    "\n",
    "It is also surprising that total basement area has a coefficient around half that of overall quality and above-ground area, given that the scatterplots looked as if all three increased price at around the same rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "32fb397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7966144593847458, 0.8382867340555185)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(Xs_train, y_train), lr.score(Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04695fb",
   "metadata": {},
   "source": [
    "Our R<sup>2</sup> of 0.79 for the training set and 0.83 for the test set indicates that there is a strong correlation within the data between the data that I chose as independent variables and the dependent variable of sale price. We do not need to change any predictors given the low bias and low variance in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b310f341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7966064676106996, 0.8382947231903262)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(alpha = 10)\n",
    "ridge.fit(Xs_train, y_train)\n",
    "\n",
    "ridge.score(Xs_train, y_train), ridge.score(Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b6d941e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7966144581729373, 0.8382856643545282)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso()\n",
    "lasso.fit(Xs_train, y_train)\n",
    "\n",
    "lasso.score(Xs_train, y_train), lasso.score(Xs_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2926fcd",
   "metadata": {},
   "source": [
    "Using the Ridge and LASSO regularization tools (with alpha for Ridge = 10 and alpha for LASSO = 1) give me almost the exact same scores as for the linear model. As such, the linear model is fine to be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b7bb5f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35865.2473217198\n",
      "31510.68790297132\n"
     ]
    }
   ],
   "source": [
    "lr_pred = lr.predict(Xs_train)\n",
    "lr_test_pred = lr.predict(Xs_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_train, lr_pred, squared = False))\n",
    "print(metrics.mean_squared_error(y_test, lr_test_pred, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aeb18247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35865.95195425227\n",
      "31509.9095307043\n"
     ]
    }
   ],
   "source": [
    "ridge_pred = ridge.predict(Xs_train)\n",
    "ridge_test_pred = ridge.predict(Xs_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_train, ridge_pred, squared = False))\n",
    "print(metrics.mean_squared_error(y_test, ridge_test_pred, squared = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2aa16444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35865.24742856567\n",
      "31510.792121255807\n"
     ]
    }
   ],
   "source": [
    "lasso_pred = lasso.predict(Xs_train)\n",
    "lasso_test_pred = lasso.predict(Xs_test)\n",
    "\n",
    "print(metrics.mean_squared_error(y_train, lasso_pred, squared = False))\n",
    "print(metrics.mean_squared_error(y_test, lasso_test_pred, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26d84d2",
   "metadata": {},
   "source": [
    "All three models lead to an RMSE of around half the baseline for both the training and test data, indicating that they do their job well as predictors. The linear model has a slightly lower RMSE than Ridge and LASSO, so it is the best of the three in predicting price accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3f42ad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding garage quality\n",
    "garage_qual = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "train['Garage Qual'] = train['Garage Qual'].map(lambda x: garage_qual.get(x))\n",
    "test['Garage Qual'] = test['Garage Qual'].map(lambda x: garage_qual.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d30516c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding garage condition\n",
    "garage_cond = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
    "train['Garage Cond'] = train['Garage Cond'].map(lambda x: garage_cond.get(x))\n",
    "test['Garage Cond'] = test['Garage Cond'].map(lambda x: garage_cond.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8e2ace55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7489726275337555\n",
      "0.7913189382481982\n",
      "39845.04604877226\n",
      "35795.34718233087\n"
     ]
    }
   ],
   "source": [
    "# Replacing overall data and condition with garage quality and condition\n",
    "X_garage = train[['Garage Cars', 'AttachedGarage', 'Garage Finish', \n",
    "                 'Garage Qual', 'Garage Cond', 'Year Built', 'Total Bsmt SF',\n",
    "                 'Residential', 'Expensive Nbrhd', 'PosProx', 'Gr Liv Area', 'WoodRoof']]\n",
    "\n",
    "y_garage = train['SalePrice']\n",
    "\n",
    "X_garage_train, X_garage_test, y_garage_train, y_garage_test = train_test_split(X_garage, y_garage, random_state = 42)\n",
    "\n",
    "# Scale the data\n",
    "ss_garage = StandardScaler()\n",
    "Xs_garage_train = ss_garage.fit_transform(X_garage_train)\n",
    "Xs_garage_test = ss_garage.transform(X_garage_test)\n",
    "\n",
    "# Get R2 score\n",
    "lr_garage = LinearRegression()\n",
    "lr_garage.fit(Xs_garage_train, y_garage_train)\n",
    "print(lr_garage.score(Xs_garage_train, y_train))\n",
    "print(lr_garage.score(Xs_garage_test, y_garage_test))\n",
    "\n",
    "# Get RMSE\n",
    "lr_pred = lr_garage.predict(Xs_garage_train)\n",
    "print(metrics.mean_squared_error(y_garage_train, lr_pred, squared = False))\n",
    "\n",
    "lr_test_pred = lr_garage.predict(Xs_garage_test)\n",
    "print(metrics.mean_squared_error(y_garage_test, lr_test_pred, squared = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbe8529",
   "metadata": {},
   "source": [
    "The R<sup>2</sup> for the model including specifically the garage quality and condition is around 0.04 less than the model which includes the overall quality and condition for both the training and test data. This result indicates that the overall measures are better are predicting price. The fact that the RMSE is 4000 higher for both training and test data supports this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "64449b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sales price for the test data using the best linear regression model\n",
    "X_test = test[['Garage Cars', 'AttachedGarage', 'Garage Finish', \n",
    "                 'Overall Qual', 'Overall Cond', 'Year Built', 'Total Bsmt SF',\n",
    "                 'Residential', 'Expensive Nbrhd', 'PosProx', 'Gr Liv Area', 'WoodRoof']]\n",
    "\n",
    "\n",
    "Xs_test = ss.transform(X_test)\n",
    "\n",
    "y_test = lr.predict(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5441826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new file with predicted sales price for each ID in the test set\n",
    "\n",
    "data = {'ID': test['Id'], 'SalePrice': y_test}\n",
    "\n",
    "test_data = pd.DataFrame(data)\n",
    "\n",
    "test_data.to_csv('../datasets/sub_reg.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e2fb6",
   "metadata": {},
   "source": [
    "## Conclusions & Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae03b8",
   "metadata": {},
   "source": [
    "Three of the seven garage variables from the initial data have a positive impact on price according to the linear model coefficients: the number of cars that can fit, the status of the interior finish, and the type of the garage. The area of the garage probably does as well given that it is largely redundant with the number of cars. It is unknown how much garage quality and condition affect price due to multicollinearity with the overall quality and condition, as well as the fact that the linear model containing the garage-specific variables is not as good of a predictor as the one with the overall components. The seventh variable, the year the garage was built, did not have enough data to use as a predictor. Further study will involve researching garage creation years, as well as the material on the garage's roof. This is because houses that are newer or which have wood roofs are more expensive, and I would like to see if those statistics for the garage also greatly increase price.\n",
    "\n",
    "It is notable that of the three main garage statistics, the one with the highest impact on price is the number of cars. Since total basement area and greater living space area also have high coefficients, it might be that the area of the house and its related enclosed components greatly increases the price. This is not true for open spaces, as the visualizations showed that the area of places like the open porch and the pool does not correlate at all with price.\n",
    "\n",
    "In conclusion, my recommendation to those who want to guess house prices based on the garage is first to look at the number of cars that could possibly fit, then if the walls are finished enough, then whether the garage is connected to the house. An external garage with a three-car space would be much more expensive than an internal garage that can only fit one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469d512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
